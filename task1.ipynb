{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca84278f-a616-4b48-8976-634ece057fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (891, 12)\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "\n",
      "First 5 rows:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "\n",
      "Missing Values:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\gudek\\OneDrive\\Desktop\\college notes\\Titanic-Dataset.csv\")\n",
    "\n",
    "# Explore basic info\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a166174e-aa08-4872-a69f-68bf995b0927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical variables:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_clean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Explore categorical variables\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCategorical variables:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_clean\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# One-hot encoding for nominal variables (no inherent order)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m df_encoded \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(df_clean, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSex\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmbarked\u001b[39m\u001b[38;5;124m'\u001b[39m], prefix\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSex\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmbarked\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_clean' is not defined"
     ]
    }
   ],
   "source": [
    "# Explore categorical variables\n",
    "print(\"Categorical variables:\")\n",
    "print(df_clean.select_dtypes(include=['object']).columns.tolist())\n",
    "\n",
    "# One-hot encoding for nominal variables (no inherent order)\n",
    "df_encoded = pd.get_dummies(df_clean, columns=['Sex', 'Embarked'], prefix=['Sex', 'Embarked'])\n",
    "\n",
    "# Label encoding for ordinal variables (if any existed)\n",
    "# For demonstration, let's encode 'Pclass' as it has ordinal nature\n",
    "le = LabelEncoder()\n",
    "df_encoded['Pclass_encoded'] = le.fit_transform(df_encoded['Pclass'])\n",
    "\n",
    "# Drop original categorical columns that we've encoded\n",
    "df_encoded.drop(['Name', 'Ticket', 'Pclass'], axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "print(\"\\nAfter encoding - Dataset shape:\", df_encoded.shape)\n",
    "print(\"Columns after encoding:\", df_encoded.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "611c2a89-5203-4804-98f9-fe608227a69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 1: INITIAL DATA EXPLORATION ===\n",
      "Dataset Shape: (891, 12)\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "\n",
      "First 5 rows:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "\n",
      "Missing Values:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "\n",
      "Basic Statistics:\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\gudek\\OneDrive\\Desktop\\college notes\\Titanic-Dataset.csv\")\n",
    "\n",
    "print(\"=== STEP 1: INITIAL DATA EXPLORATION ===\")\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e23a5be6-5a79-4348-b7e3-26d8652bc457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STEP 2: HANDLING MISSING VALUES ===\n",
      "Missing values before handling:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "Filled 177 missing Age values with median: 28.0\n",
      "Filled 2 missing Embarked values with mode: S\n",
      "Dropped Cabin column with 687 missing values (77.1% missing)\n",
      "\n",
      "Missing values after handling:\n",
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Handle Missing Values\n",
    "print(\"\\n=== STEP 2: HANDLING MISSING VALUES ===\")\n",
    "\n",
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Display missing values before handling\n",
    "print(\"Missing values before handling:\")\n",
    "print(df_clean.isnull().sum())\n",
    "\n",
    "# Handle missing values strategically\n",
    "# Age - fill with median (less sensitive to outliers)\n",
    "age_median = df_clean['Age'].median()\n",
    "df_clean['Age'].fillna(age_median, inplace=True)\n",
    "print(f\"Filled {df['Age'].isnull().sum()} missing Age values with median: {age_median}\")\n",
    "\n",
    "# Embarked - fill with mode (most frequent value)\n",
    "embarked_mode = df_clean['Embarked'].mode()[0]\n",
    "df_clean['Embarked'].fillna(embarked_mode, inplace=True)\n",
    "print(f\"Filled {df['Embarked'].isnull().sum()} missing Embarked values with mode: {embarked_mode}\")\n",
    "\n",
    "# Cabin - too many missing values, drop the column\n",
    "cabin_missing = df_clean['Cabin'].isnull().sum()\n",
    "df_clean.drop('Cabin', axis=1, inplace=True)\n",
    "print(f\"Dropped Cabin column with {cabin_missing} missing values ({cabin_missing/len(df)*100:.1f}% missing)\")\n",
    "\n",
    "# Verify missing values after handling\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(df_clean.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fda8b52c-32c0-4337-b7ef-80aa41e61ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STEP 3: HANDLING CATEGORICAL FEATURES ===\n",
      "Categorical variables:\n",
      "['Name', 'Sex', 'Ticket', 'Embarked']\n",
      "\n",
      "Unique values in categorical columns:\n",
      "Name: 891 unique values\n",
      "Sex: 2 unique values\n",
      "   Values: ['male' 'female']\n",
      "Ticket: 681 unique values\n",
      "Embarked: 3 unique values\n",
      "   Values: ['S' 'C' 'Q']\n",
      "\n",
      "Performing one-hot encoding...\n",
      "\n",
      "After encoding - Dataset shape: (891, 13)\n",
      "Columns after encoding:\n",
      "['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Pclass_encoded']\n",
      "\n",
      "First 3 rows after encoding:\n",
      "   PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare  Sex_female  \\\n",
      "0            1         0       3  22.0      1      0   7.2500       False   \n",
      "1            2         1       1  38.0      1      0  71.2833        True   \n",
      "2            3         1       3  26.0      0      0   7.9250        True   \n",
      "\n",
      "   Sex_male  Embarked_C  Embarked_Q  Embarked_S  Pclass_encoded  \n",
      "0      True       False       False        True               2  \n",
      "1     False        True       False       False               0  \n",
      "2     False       False       False        True               2  \n"
     ]
    }
   ],
   "source": [
    "# Step 3: Convert Categorical Features\n",
    "print(\"\\n=== STEP 3: HANDLING CATEGORICAL FEATURES ===\")\n",
    "\n",
    "# Explore categorical variables\n",
    "print(\"Categorical variables:\")\n",
    "categorical_cols = df_clean.select_dtypes(include=['object']).columns.tolist()\n",
    "print(categorical_cols)\n",
    "\n",
    "print(\"\\nUnique values in categorical columns:\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"{col}: {df_clean[col].nunique()} unique values\")\n",
    "    if df_clean[col].nunique() < 10:  # Show values for columns with few categories\n",
    "        print(f\"   Values: {df_clean[col].unique()}\")\n",
    "\n",
    "# One-hot encoding for nominal variables\n",
    "print(\"\\nPerforming one-hot encoding...\")\n",
    "df_encoded = pd.get_dummies(df_clean, columns=['Sex', 'Embarked'], prefix=['Sex', 'Embarked'])\n",
    "\n",
    "# For demonstration, let's also encode Pclass\n",
    "le = LabelEncoder()\n",
    "df_encoded['Pclass_encoded'] = le.fit_transform(df_encoded['Pclass'])\n",
    "\n",
    "# Drop original categorical columns that are not needed\n",
    "columns_to_drop = ['Name', 'Ticket']  # Keeping 'Pclass' for reference\n",
    "df_encoded.drop(columns_to_drop, axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "print(f\"\\nAfter encoding - Dataset shape: {df_encoded.shape}\")\n",
    "print(\"Columns after encoding:\")\n",
    "print(df_encoded.columns.tolist())\n",
    "print(\"\\nFirst 3 rows after encoding:\")\n",
    "print(df_encoded.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1102ade-bf59-4249-bbfd-9ce35ccb08d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STEP 4: FEATURE SCALING ===\n",
      "Before standardization:\n",
      "              Age       SibSp       Parch        Fare\n",
      "count  891.000000  891.000000  891.000000  891.000000\n",
      "mean    29.361582    0.523008    0.381594   32.204208\n",
      "std     13.019697    1.102743    0.806057   49.693429\n",
      "min      0.420000    0.000000    0.000000    0.000000\n",
      "25%     22.000000    0.000000    0.000000    7.910400\n",
      "50%     28.000000    0.000000    0.000000   14.454200\n",
      "75%     35.000000    1.000000    0.000000   31.000000\n",
      "max     80.000000    8.000000    6.000000  512.329200\n",
      "\n",
      "After standardization:\n",
      "                Age         SibSp         Parch          Fare\n",
      "count  8.910000e+02  8.910000e+02  8.910000e+02  8.910000e+02\n",
      "mean   2.272780e-16  4.386066e-17  5.382900e-17  3.987333e-18\n",
      "std    1.000562e+00  1.000562e+00  1.000562e+00  1.000562e+00\n",
      "min   -2.224156e+00 -4.745452e-01 -4.736736e-01 -6.484217e-01\n",
      "25%   -5.657365e-01 -4.745452e-01 -4.736736e-01 -4.891482e-01\n",
      "50%   -1.046374e-01 -4.745452e-01 -4.736736e-01 -3.573909e-01\n",
      "75%    4.333115e-01  4.327934e-01 -4.736736e-01 -2.424635e-02\n",
      "max    3.891554e+00  6.784163e+00  6.974147e+00  9.667167e+00\n",
      "\n",
      "--- For comparison: Normalization ---\n",
      "After normalization (min=0, max=1):\n",
      "              Age       SibSp       Parch        Fare\n",
      "count  891.000000  891.000000  891.000000  891.000000\n",
      "mean     0.363679    0.065376    0.063599    0.062858\n",
      "std      0.163605    0.137843    0.134343    0.096995\n",
      "min      0.000000    0.000000    0.000000    0.000000\n",
      "25%      0.271174    0.000000    0.000000    0.015440\n",
      "50%      0.346569    0.000000    0.000000    0.028213\n",
      "75%      0.434531    0.125000    0.000000    0.060508\n",
      "max      1.000000    1.000000    1.000000    1.000000\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Normalize/Standardize Numerical Features\n",
    "print(\"\\n=== STEP 4: FEATURE SCALING ===\")\n",
    "\n",
    "# Select numerical features for scaling\n",
    "numerical_features = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "\n",
    "print(\"Before standardization:\")\n",
    "print(df_encoded[numerical_features].describe())\n",
    "\n",
    "# Standardization (mean=0, std=1)\n",
    "scaler_standard = StandardScaler()\n",
    "df_encoded[numerical_features] = scaler_standard.fit_transform(df_encoded[numerical_features])\n",
    "\n",
    "print(\"\\nAfter standardization:\")\n",
    "print(df_encoded[numerical_features].describe())\n",
    "\n",
    "# Demonstrate the difference with Normalization\n",
    "print(\"\\n--- For comparison: Normalization ---\")\n",
    "df_normalized = df_clean.copy()\n",
    "scaler_minmax = MinMaxScaler()\n",
    "df_normalized[numerical_features] = scaler_minmax.fit_transform(df_normalized[numerical_features])\n",
    "print(\"After normalization (min=0, max=1):\")\n",
    "print(df_normalized[numerical_features].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fa43a9-8f1b-49e1-a47c-c7d9546c755b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
